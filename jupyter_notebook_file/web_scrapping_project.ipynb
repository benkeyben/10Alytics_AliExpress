{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries and modules\n",
    "import json\n",
    "import csv\n",
    "import requests\n",
    "import logging\n",
    "import logging\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_json_data(params):\n",
    "    \"\"\"\n",
    "    This function retrieves json data from the specified URL. \n",
    "    If an error occurs while retrieving the data, the function \n",
    "    logs the error message\n",
    "    \"\"\"\n",
    "    url = params['urls'][0]\n",
    "    headers = params['headers']\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        data = response.json()\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logging.error(\n",
    "            f\"An error occurred while retrieving data from {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json_data(params, data):\n",
    "    \"\"\"\n",
    "    This function writes json data to a specific file.\n",
    "    If an error occurs while writing the data, the function\n",
    "    logs the error message\n",
    "    \"\"\"\n",
    "    filename = params['filenames'][0]\n",
    "    try:\n",
    "        with open(filename, 'w') as json_file:\n",
    "            print(f\"Response is sucessful. Writing json data to {filename}.\")\n",
    "            json.dump(data, json_file)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while saving data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(params):\n",
    "    \"\"\"\n",
    "    This function cleans and organizes data in dataframes and write them to csv files. \n",
    "    If an error occurs while processing the data, the function logs the error message\n",
    "    \"\"\"\n",
    "    if type(params[0]) == str:\n",
    "        try:\n",
    "            df = pd.read_json(params[0])\n",
    "            flat_df = pd.json_normalize(df[params[1]])\n",
    "            flat_df = flat_df.drop_duplicates(subset=['id'])\n",
    "            flat_df['category_id'] = flat_df['id']\n",
    "            flat_df['category_name'] = flat_df['name']\n",
    "            flat_df['category_name'] = flat_df['category_name'].astype(str)\n",
    "            flat_df['category_id'] = flat_df['category_id'].astype(int)\n",
    "            flat_df.drop(['id', 'name', 'link'], axis=1, inplace=True)\n",
    "            flat_df.to_csv(params[2][0], index=False)\n",
    "        except Exception as e:\n",
    "            logging.error(\n",
    "                f\"An error occurred while creating csv file {params[2][0]}: {e}\")\n",
    "    elif type(params[0]) == list:\n",
    "        try:\n",
    "            obj = {}\n",
    "            obj['laptop_name'] = params[0]\n",
    "            obj['quantity_sold'] = params[1]\n",
    "            obj['unit_price'] = params[2]\n",
    "            obj['shipping_cost'] = params[3]\n",
    "            obj['store_name'] = params[4]\n",
    "            obj['discount_percent'] = params[5]\n",
    "            df = pd.DataFrame.from_dict(obj, orient='index')\n",
    "            df = df.transpose()\n",
    "\n",
    "            # create a series of numbers from 1 to the len of df for laptop_id\n",
    "            df = df.assign(laptop_id=pd.Series(\n",
    "                range(1, len(df)+1), dtype=\"int\"))\n",
    "\n",
    "            # Converting laptop_name from object type to string type\n",
    "            df[\"laptop_name\"] = df[\"laptop_name\"].astype(str)\n",
    "\n",
    "            df[\"quantity_sold\"] = df[\"quantity_sold\"].str.replace(\n",
    "                '[^0-9]', '', regex=True)\n",
    "            df[\"quantity_sold\"] = df[\"quantity_sold\"].fillna('0')\n",
    "            df[\"quantity_sold\"] = df[\"quantity_sold\"].astype(int)\n",
    "\n",
    "            df['unit_price'] = df['unit_price'].str.replace(\n",
    "                '[^0-9.]', '', regex=True)\n",
    "            df['unit_price'] = df['unit_price'].astype(float)\n",
    "\n",
    "            df['shipping_cost'] = df['shipping_cost'].str.replace(\n",
    "                'Free shipping', '0', regex=True)\n",
    "            df['shipping_cost'] = df['shipping_cost'].str.replace(\n",
    "                '[^0-9.]', '', regex=True)\n",
    "            df['shipping_cost'] = df['shipping_cost'].astype(float)\n",
    "\n",
    "            df['discount_percent'] = df['discount_percent'].str.replace(\n",
    "                '[^0-9]', '', regex=True)\n",
    "            df['discount_percent'] = df['discount_percent'].fillna('0')\n",
    "            df['discount_percent'] = df['discount_percent'].astype(float)\n",
    "\n",
    "            # create category_id column in df with default id of 702 (laptop)\n",
    "            df = df.assign(category_id=702)\n",
    "\n",
    "            # Placing laptop_id as the first column in  df\n",
    "            laptop_id_col = df.pop('laptop_id')\n",
    "            df.insert(0, 'laptop_id', laptop_id_col)\n",
    "\n",
    "            laptop_df = df.copy()\n",
    "\n",
    "            laptop_df.drop(['unit_price', 'quantity_sold',\n",
    "                            'shipping_cost', 'discount_percent'], axis=1, inplace=True)\n",
    "\n",
    "            laptop_df.to_csv(\"laptop.csv\", index=False)\n",
    "\n",
    "            # Drop rows where quantity is 0 in order to create sales tables\n",
    "            for x in df.index:\n",
    "                if df.loc[x, \"quantity_sold\"] == 0:\n",
    "                    df.drop(x, inplace=True)\n",
    "\n",
    "            df.drop(['store_name', 'category_id',\n",
    "                     'laptop_name'], axis=1, inplace=True)\n",
    "\n",
    "            df = df.assign(sales_id=pd.Series(\n",
    "                range(1, len(df)+1), dtype=\"int\"))\n",
    "\n",
    "            first_col = df.pop('sales_id')\n",
    "            df.insert(0, 'sales_id', first_col)\n",
    "\n",
    "            sales_df = df.copy()\n",
    "            sales_df.to_csv(\"sales.csv\", index=False)\n",
    "            print(\"Data is successfully extracted, cleaned and loaded into csv files.\")\n",
    "        except Exception as e:\n",
    "            logging.error(\n",
    "                f\"An error occurred while cleaning or loading data into csv files: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_html(response, tag, attribute):\n",
    "    \"\"\"\n",
    "    This function parses the HTML content of the response \n",
    "    and returns a list of text data for the specified HTML \n",
    "    tag and class attribute. If an error occurs while parsing \n",
    "    the HTML content, the function logs the error message. \n",
    "    \"\"\"\n",
    "    if response is None:\n",
    "        return None\n",
    "    try:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        data_list = soup.find_all(tag, class_=attribute)\n",
    "        return [data.text for data in data_list]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while parsing HTML content: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_html_data(params):\n",
    "    \"\"\"\n",
    "    This function retrieves the HTML content of the website, \n",
    "    and then calls the parse_html function to extract the \n",
    "    relevant information. The information is returned as a list of lists\n",
    "    \"\"\"\n",
    "    start = params['webpages']['start']\n",
    "    end = params['webpages']['end']\n",
    "    tags = params['tags']\n",
    "    attributes = params['attributes']\n",
    "    all_list = params['all_list']\n",
    "    for num in range(start, end):\n",
    "        try:\n",
    "            response = requests.get(params['urls'][1])\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as err:\n",
    "            print(f\"An error occurred: {err}\")\n",
    "            break\n",
    "        else:\n",
    "            print(\n",
    "                f\"Response is sucessful. Extracting html data from webpage {num}.\")\n",
    "            for i in range(0, len(tags)):\n",
    "                all_list[i] += parser_html(response, tags[i], attributes[i])\n",
    "            url = f'https://www.aliexpress.com/w/wholesale-laptop.html?page={num+1}&g=y&SearchText=laptop'\n",
    "    return all_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_connect(params):\n",
    "    \"\"\"\n",
    "    This function creates a connection to the database using the\n",
    "    parameter passed into it and returns the connection object\n",
    "    \"\"\"\n",
    "    conn = psycopg2.connect(\n",
    "        database=params['database'],\n",
    "        user=params['user'],\n",
    "        password=params['password'],\n",
    "        host=params['host'],\n",
    "        port=params['port']\n",
    "    )\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql_stmt_list is a list of sql statements to create schema and tables and insert\n",
    "sql_stmt_list = [\n",
    "    [\n",
    "        \"DROP DATABASE IF EXISTS AliExpress;\",\n",
    "        \"CREATE AliExpress;\",\n",
    "        \"CREATE SCHEMA lap;\",\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS lap.category (\n",
    "            category_id INTEGER PRIMARY KEY,\n",
    "            category_name VARCHAR(255)\n",
    "        );\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS lap.laptop (\n",
    "            laptop_id SERIAL PRIMARY KEY,\n",
    "            laptop_name VARCHAR(255),\n",
    "            store_name VARCHAR(255), \n",
    "            category_id INTEGER\n",
    "        );\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS lap.sales (\n",
    "            sales_id SERIAL PRIMARY KEY,\n",
    "            laptop_id INTEGER,\n",
    "            unit_price DECIMAL(10, 2),\n",
    "            quantity_sold INTEGER, \n",
    "            discount_percent DECIMAL(10, 2),\n",
    "            shipping_cost DECIMAL(10, 2),\n",
    "            FOREIGN KEY (laptop_id) REFERENCES lap.laptop(laptop_id)\n",
    "        );\n",
    "        \"\"\"\n",
    "    ],\n",
    "    [\n",
    "        \"INSERT INTO lap.category (category_id,category_name) VALUES (%s, %s);\",\n",
    "        \"\"\"INSERT INTO lap.laptop (laptop_id,laptop_name,store_name,category_id) VALUES (%s, %s, %s, %s);\"\"\",\n",
    "        \"\"\"INSERT INTO lap.sales (sales_id,laptop_id,quantity_sold,unit_price,discount_percent,shipping_cost) VALUES (%s, %s, %s, %s, %s, %s);\"\"\"\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tables(sql_stmt_list, conn):\n",
    "    \"\"\"\n",
    "    This function executes the sql statement object to create tables and schema and closes the\n",
    "    connection. It accepts sql statement list, and connection object\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    for stmt in sql_stmt_list[0]:\n",
    "        cursor.execute(stmt)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(params, conn, sql_stmt_list):\n",
    "    \"\"\"\n",
    "    This function loads the data in csv files into their repective tables in\n",
    "    the database postgres. It accepts a list of csv files, connection object\n",
    "    and sql statement parameters\n",
    "    \"\"\"\n",
    "    sql_stmt = sql_stmt_list[1]\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Loading data into tables in database.\")\n",
    "    for i, csv_file in enumerate(params['filenames'][2]):\n",
    "        try:\n",
    "            with open(csv_file, 'r') as file:\n",
    "                reader = csv.reader(file)\n",
    "                next(reader)  # skip the header row\n",
    "                for row in reader:\n",
    "                    cursor.execute(sql_stmt[i], row)\n",
    "            print(\n",
    "                f\"Finished loading data into {params['table_names'][i]} tables\")\n",
    "        except Exception as e:\n",
    "            logging.error(\n",
    "                f\"An error occurred while loading data into {params['table_names'][i]} tables: {e}\")\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    This function executes the other functions and regulate\n",
    "    the whole program\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'database': 'AliExpress',\n",
    "        'user': 'postgres',\n",
    "        'password': 'password',\n",
    "        'host': 'localhost',\n",
    "        'port': '5432',\n",
    "        'table_names': ['lap.category', 'lap.laptop', 'lap.sales'],\n",
    "        \"filenames\": ['categories.json', 'categories', ['category.csv', 'laptop.csv', 'sales.csv']],\n",
    "        'urls': [\n",
    "                    \"https://ali-express1.p.rapidapi.com/categories\",\n",
    "                    \"https://www.aliexpress.com/w/wholesale-laptop.html?g=y&SearchText=laptop\"\n",
    "        ],\n",
    "        'headers': {\n",
    "            \"X-RapidAPI-Key\": \"664a752285msh4ae3ff3d99b12a1p13a3e9jsn5dbb9e535753\",\n",
    "            \"X-RapidAPI-Host\": \"ali-express1.p.rapidapi.com\"\n",
    "        },\n",
    "        'webpages': {\n",
    "            'start': 1,\n",
    "            'end': 5\n",
    "        },\n",
    "        'tags': [\"h1\", \"span\", \"div\", \"span\", \"span\", \"span\"],\n",
    "        'attributes': [\n",
    "            \"multi--titleText--nXeOvyr\",\n",
    "            \"multi--trade--Ktbl2jB\",\n",
    "            \"multi--price-sale--U-S0jtj\",\n",
    "            \"tag--text--1BSEXVh tag--textStyle--3dc7wLU multi--serviceStyle--1Z6RxQ4\",\n",
    "            \"cards--store--3GyJcot\",\n",
    "            \"tag--text--1BSEXVh tag--textStyle--3dc7wLU multi--superStyle--1jUmObG\"\n",
    "        ],\n",
    "        # The length of the all_list must be the same as the length of tags or attributes\n",
    "        'all_list': [[], [], [], [], [], []]\n",
    "    }\n",
    "\n",
    "    json_data = request_json_data(params)\n",
    "    if json_data is not None:\n",
    "        write_json_data(params, json_data)\n",
    "        data_cleaning(params['filenames'])\n",
    "\n",
    "    all_list = request_html_data(params)\n",
    "    data_cleaning(all_list)\n",
    "    connection = db_connect(params)\n",
    "    create_tables(sql_stmt_list, connection)\n",
    "    insert_data(params, connection, sql_stmt_list)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
